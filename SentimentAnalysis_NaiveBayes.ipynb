{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFVPhVtbi0Ryh4FhI/axsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeThanhLong2001/SentimentAnalysis-NaiveBayes/blob/main/SentimentAnalysis_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes Classfier for Sentiment Analysis on Tweets\n",
        "**Ph√¢n t√≠ch c·∫£m x√∫c tr√™n t·∫≠p 1Tweets1 s·ª≠ d·ª•ng thu·∫≠t to√°n ph√¢n lo·∫°i Naive Bayes**"
      ],
      "metadata": {
        "id": "LAxUmFbie9s2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbTyQ19kY38A",
        "outputId": "43b7fcf3-4014-43e0-eb70-580cbe50aaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T·∫£i v·ªÅ t·∫≠p d·ªØ li·ªáu tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# Chia th√†nh 2 t·∫≠p train v√† test\n",
        "# train: 4000 samples, test: 1000 samples\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# Tao nhan negative:0, positive:1\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ],
      "metadata": {
        "id": "FdmGv3mOfE0o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "HECzXmiLgbYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZEkeNbBgTlD",
        "outputId": "e5b1495f-7fb4-41e2-f050-204297f214b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days',\n",
              " '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM',\n",
              " \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\",\n",
              " '@Impatientraider On second thought, there‚Äôs just not enough time for a DD :) But new shorts entering system. Sheep must be buying.',\n",
              " 'Jgh , but we have to go to Bayan :D bye',\n",
              " 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell‚Ä¶ as the name implies :p.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_preprocess(text):\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "\n",
        "    text = re.sub(r'#', '', text)\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    text_tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    text_clean = []\n",
        "    for word in text_tokens:\n",
        "        if word not in string.punctuation:\n",
        "            text_clean.append(word)\n",
        "\n",
        "    return text_clean"
      ],
      "metadata": {
        "id": "HmXcIObMghAT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"RT @Twitter @chapagain Hello There! Have a great day. #good #morning http://chapagain.com.np\"\n",
        "basic_preprocess(example_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KLAETI3he00",
        "outputId": "09e88e80-494b-4ecf-858e-50470a202513"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'there', 'have', 'a', 'great', 'day', 'good', 'morning']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Buid Vocab"
      ],
      "metadata": {
        "id": "niDv9rUBibJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_freq_words(corpus, labels):\n",
        "    \"\"\" X√¢y d·ª±ng b·ªô t·ª´ ƒëi·ªÉn t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa c√°c t·ª´\n",
        "    Args:\n",
        "        corpus: t·∫≠p danh s√°ch c√°c c√¢u\n",
        "        labels: t·∫≠p nh√£n t∆∞∆°ng ·ª©ng v·ªõi c√°c c√¢u trong corpus (0 ho·∫∑c 1)\n",
        "    Output:\n",
        "        model: b·ªô t·ª´ ƒëi·ªÉn √°nh x·∫° m·ªói t·ª´ v√† t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa t·ª´ ƒë√≥ trong corpus\n",
        "            key: (word, label)\n",
        "            value: frequency\n",
        "            VD: {('boring', 0): 2} => t·ª´ boring xu·∫•t hi·ªán 2 l·∫ßn trong c√°c sample thu·ªôc class 0\n",
        "    \"\"\"\n",
        "    model = {}\n",
        "    for label, sentence in zip(labels, corpus):\n",
        "        for word in basic_preprocess(sentence):\n",
        "            # ƒê·ªãnh nghƒ©a key c·ªßa model l√† tuple (word, label)\n",
        "            pair = (word, label)\n",
        "            # N·∫øu key ƒë√£ t·ªìn t·∫°i trong model th√¨ tƒÉng value l√™n 1\n",
        "            if pair in model:\n",
        "                model[pair] += 1\n",
        "            # N·∫øu key ch∆∞a t·ªìn t·∫°i trong model th√¨ b·ªï sung key v√†o model v·ªõi value =1\n",
        "            else:\n",
        "                model[pair] = 1\n",
        "    return model"
      ],
      "metadata": {
        "id": "xpFDxj_nidcB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = count_freq_words(train_x, train_y)\n",
        "freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQXpUliuiq8Z",
        "outputId": "65e855ba-6a6d-4acc-c611-2ef397fd6097"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('followfriday', 1.0): 23,\n",
              " ('for', 1.0): 606,\n",
              " ('being', 1.0): 49,\n",
              " ('top', 1.0): 29,\n",
              " ('engaged', 1.0): 7,\n",
              " ('members', 1.0): 11,\n",
              " ('in', 1.0): 381,\n",
              " ('my', 1.0): 441,\n",
              " ('community', 1.0): 25,\n",
              " ('this', 1.0): 242,\n",
              " ('week', 1.0): 61,\n",
              " (':)', 1.0): 2847,\n",
              " ('hey', 1.0): 60,\n",
              " ('james', 1.0): 7,\n",
              " ('how', 1.0): 60,\n",
              " ('odd', 1.0): 1,\n",
              " (':/', 1.0): 5,\n",
              " ('please', 1.0): 77,\n",
              " ('call', 1.0): 21,\n",
              " ('our', 1.0): 111,\n",
              " ('contact', 1.0): 4,\n",
              " ('centre', 1.0): 1,\n",
              " ('on', 1.0): 242,\n",
              " ('02392441234', 1.0): 1,\n",
              " ('and', 1.0): 553,\n",
              " ('we', 1.0): 182,\n",
              " ('will', 1.0): 150,\n",
              " ('be', 1.0): 198,\n",
              " ('able', 1.0): 6,\n",
              " ('to', 1.0): 836,\n",
              " ('assist', 1.0): 1,\n",
              " ('you', 1.0): 1187,\n",
              " ('many', 1.0): 28,\n",
              " ('thanks', 1.0): 311,\n",
              " ('had', 1.0): 35,\n",
              " ('a', 1.0): 725,\n",
              " ('listen', 1.0): 8,\n",
              " ('last', 1.0): 36,\n",
              " ('night', 1.0): 50,\n",
              " ('as', 1.0): 82,\n",
              " ('bleed', 1.0): 2,\n",
              " ('is', 1.0): 354,\n",
              " ('an', 1.0): 99,\n",
              " ('amazing', 1.0): 39,\n",
              " ('track', 1.0): 5,\n",
              " ('when', 1.0): 69,\n",
              " ('are', 1.0): 152,\n",
              " ('scotland', 1.0): 2,\n",
              " ('congrats', 1.0): 15,\n",
              " ('yeaaah', 1.0): 1,\n",
              " ('yipppy', 1.0): 1,\n",
              " ('accnt', 1.0): 2,\n",
              " ('verified', 1.0): 1,\n",
              " ('rqst', 1.0): 1,\n",
              " ('has', 1.0): 38,\n",
              " ('succeed', 1.0): 1,\n",
              " ('got', 1.0): 57,\n",
              " ('blue', 1.0): 8,\n",
              " ('tick', 1.0): 1,\n",
              " ('mark', 1.0): 1,\n",
              " ('fb', 1.0): 4,\n",
              " ('profile', 1.0): 2,\n",
              " ('15', 1.0): 4,\n",
              " ('days', 1.0): 30,\n",
              " ('one', 1.0): 87,\n",
              " ('irresistible', 1.0): 2,\n",
              " ('flipkartfashionfriday', 1.0): 16,\n",
              " (\"don't\", 1.0): 69,\n",
              " ('like', 1.0): 177,\n",
              " ('keep', 1.0): 46,\n",
              " ('lovely', 1.0): 48,\n",
              " ('customers', 1.0): 2,\n",
              " ('waiting', 1.0): 23,\n",
              " ('long', 1.0): 27,\n",
              " ('hope', 1.0): 98,\n",
              " ('enjoy', 1.0): 42,\n",
              " ('happy', 1.0): 149,\n",
              " ('friday', 1.0): 86,\n",
              " ('lwwf', 1.0): 1,\n",
              " ('second', 1.0): 8,\n",
              " ('thought', 1.0): 20,\n",
              " ('there', 1.0): 67,\n",
              " ('‚Äô', 1.0): 17,\n",
              " ('s', 1.0): 26,\n",
              " ('just', 1.0): 165,\n",
              " ('not', 1.0): 115,\n",
              " ('enough', 1.0): 16,\n",
              " ('time', 1.0): 89,\n",
              " ('dd', 1.0): 1,\n",
              " ('but', 1.0): 142,\n",
              " ('new', 1.0): 111,\n",
              " ('shorts', 1.0): 1,\n",
              " ('entering', 1.0): 1,\n",
              " ('system', 1.0): 2,\n",
              " ('sheep', 1.0): 1,\n",
              " ('must', 1.0): 14,\n",
              " ('buying', 1.0): 1,\n",
              " ('jgh', 1.0): 4,\n",
              " ('have', 1.0): 344,\n",
              " ('go', 1.0): 68,\n",
              " ('bayan', 1.0): 1,\n",
              " (':D', 1.0): 498,\n",
              " ('bye', 1.0): 5,\n",
              " ('act', 1.0): 4,\n",
              " ('of', 1.0): 329,\n",
              " ('mischievousness', 1.0): 1,\n",
              " ('am', 1.0): 63,\n",
              " ('calling', 1.0): 4,\n",
              " ('the', 1.0): 873,\n",
              " ('etl', 1.0): 1,\n",
              " ('layer', 1.0): 1,\n",
              " ('in-house', 1.0): 1,\n",
              " ('warehousing', 1.0): 1,\n",
              " ('app', 1.0): 11,\n",
              " ('katamari', 1.0): 1,\n",
              " ('well', 1.0): 66,\n",
              " ('‚Ä¶', 1.0): 31,\n",
              " ('name', 1.0): 10,\n",
              " ('implies', 1.0): 1,\n",
              " (':p', 1.0): 103,\n",
              " ('influencers', 1.0): 10,\n",
              " ('who', 1.0): 42,\n",
              " (\"wouldn't\", 1.0): 6,\n",
              " ('love', 1.0): 225,\n",
              " ('these', 1.0): 18,\n",
              " ('big', 1.0): 27,\n",
              " ('...', 1.0): 227,\n",
              " ('juicy', 1.0): 3,\n",
              " ('selfies', 1.0): 6,\n",
              " ('follow', 1.0): 211,\n",
              " ('perfect', 1.0): 16,\n",
              " ('so', 1.0): 232,\n",
              " ('already', 1.0): 19,\n",
              " ('know', 1.0): 113,\n",
              " (\"what's\", 1.0): 14,\n",
              " ('great', 1.0): 134,\n",
              " ('opportunity', 1.0): 2,\n",
              " ('junior', 1.0): 2,\n",
              " ('triathletes', 1.0): 1,\n",
              " ('aged', 1.0): 1,\n",
              " ('12', 1.0): 5,\n",
              " ('13', 1.0): 5,\n",
              " ('at', 1.0): 144,\n",
              " ('gatorade', 1.0): 1,\n",
              " ('series', 1.0): 4,\n",
              " ('get', 1.0): 135,\n",
              " ('your', 1.0): 263,\n",
              " ('entries', 1.0): 1,\n",
              " ('laying', 1.0): 2,\n",
              " ('out', 1.0): 87,\n",
              " ('greetings', 1.0): 3,\n",
              " ('card', 1.0): 5,\n",
              " ('range', 1.0): 1,\n",
              " ('print', 1.0): 1,\n",
              " ('today', 1.0): 86,\n",
              " ('job', 1.0): 33,\n",
              " (':-)', 1.0): 543,\n",
              " (\"friend's\", 1.0): 3,\n",
              " ('lunch', 1.0): 3,\n",
              " ('yummm', 1.0): 1,\n",
              " ('nostalgia', 1.0): 1,\n",
              " ('tbs', 1.0): 1,\n",
              " ('ku', 1.0): 1,\n",
              " ('it', 1.0): 396,\n",
              " ('id', 1.0): 7,\n",
              " ('conflict', 1.0): 1,\n",
              " ('help', 1.0): 29,\n",
              " (\"here's\", 1.0): 20,\n",
              " ('screenshot', 1.0): 1,\n",
              " ('working', 1.0): 28,\n",
              " ('hi', 1.0): 154,\n",
              " ('liv', 1.0): 2,\n",
              " ('hello', 1.0): 49,\n",
              " ('i', 1.0): 877,\n",
              " ('need', 1.0): 47,\n",
              " ('something', 1.0): 25,\n",
              " ('can', 1.0): 167,\n",
              " ('u', 1.0): 136,\n",
              " ('fm', 1.0): 2,\n",
              " ('me', 1.0): 271,\n",
              " ('twitter', 1.0): 25,\n",
              " ('‚Äî', 1.0): 22,\n",
              " ('sure', 1.0): 35,\n",
              " ('thing', 1.0): 26,\n",
              " ('dm', 1.0): 31,\n",
              " ('x', 1.0): 50,\n",
              " ('followers', 1.0): 26,\n",
              " (\"i've\", 1.0): 25,\n",
              " ('heard', 1.0): 9,\n",
              " ('four', 1.0): 5,\n",
              " ('seasons', 1.0): 1,\n",
              " ('pretty', 1.0): 17,\n",
              " ('dope', 1.0): 2,\n",
              " ('penthouse', 1.0): 1,\n",
              " ('obvs', 1.0): 1,\n",
              " ('gobigorgohome', 1.0): 1,\n",
              " ('fun', 1.0): 45,\n",
              " (\"y'all\", 1.0): 3,\n",
              " ('yeah', 1.0): 30,\n",
              " ('suppose', 1.0): 5,\n",
              " ('she', 1.0): 69,\n",
              " ('was', 1.0): 116,\n",
              " ('lol', 1.0): 47,\n",
              " ('chat', 1.0): 9,\n",
              " ('bit', 1.0): 15,\n",
              " ('off', 1.0): 28,\n",
              " ('youth', 1.0): 14,\n",
              " ('opportunities', 1.0): 14,\n",
              " ('üíÖüèΩ', 1.0): 1,\n",
              " ('üíã', 1.0): 2,\n",
              " (\"haven't\", 1.0): 12,\n",
              " ('seen', 1.0): 6,\n",
              " ('years', 1.0): 10,\n",
              " ('thank', 1.0): 192,\n",
              " ('rest', 1.0): 9,\n",
              " ('goes', 1.0): 4,\n",
              " ('by', 1.0): 31,\n",
              " ('quickly', 1.0): 3,\n",
              " ('bed', 1.0): 8,\n",
              " ('music', 1.0): 15,\n",
              " ('fix', 1.0): 3,\n",
              " ('now', 1.0): 90,\n",
              " ('dream', 1.0): 13,\n",
              " ('spiritual', 1.0): 1,\n",
              " ('ritual', 1.0): 1,\n",
              " ('festival', 1.0): 7,\n",
              " ('n√©pal', 1.0): 1,\n",
              " ('beginning', 1.0): 3,\n",
              " ('line-up', 1.0): 4,\n",
              " ('left', 1.0): 10,\n",
              " ('y', 1.0): 5,\n",
              " ('see', 1.0): 142,\n",
              " ('more', 1.0): 80,\n",
              " ('sarah', 1.0): 4,\n",
              " ('send', 1.0): 7,\n",
              " ('us', 1.0): 91,\n",
              " ('email', 1.0): 19,\n",
              " ('bitsy@bitdefender.com', 1.0): 1,\n",
              " (\"we'll\", 1.0): 12,\n",
              " ('asap', 1.0): 5,\n",
              " ('lols', 1.0): 1,\n",
              " ('kik', 1.0): 16,\n",
              " ('hatessuce', 1.0): 1,\n",
              " ('32429', 1.0): 1,\n",
              " ('kikme', 1.0): 1,\n",
              " ('lgbt', 1.0): 2,\n",
              " ('tinder', 1.0): 1,\n",
              " ('nsfw', 1.0): 1,\n",
              " ('akua', 1.0): 1,\n",
              " ('cumshot', 1.0): 1,\n",
              " ('come', 1.0): 42,\n",
              " ('house', 1.0): 4,\n",
              " ('nsn_supplements', 1.0): 1,\n",
              " ('effective', 1.0): 1,\n",
              " ('press', 1.0): 1,\n",
              " ('release', 1.0): 8,\n",
              " ('distribution', 1.0): 1,\n",
              " ('with', 1.0): 178,\n",
              " ('results', 1.0): 2,\n",
              " ('link', 1.0): 10,\n",
              " ('removed', 1.0): 2,\n",
              " ('pressrelease', 1.0): 1,\n",
              " ('newsdistribution', 1.0): 1,\n",
              " ('bam', 1.0): 44,\n",
              " ('bestfriend', 1.0): 49,\n",
              " ('loves', 1.0): 50,\n",
              " ('lot', 1.0): 71,\n",
              " ('warsaw', 1.0): 44,\n",
              " ('<3', 1.0): 118,\n",
              " ('x46', 1.0): 1,\n",
              " ('everyone', 1.0): 45,\n",
              " ('watch', 1.0): 16,\n",
              " ('documentary', 1.0): 1,\n",
              " ('earthlings', 1.0): 1,\n",
              " ('youtube', 1.0): 7,\n",
              " ('supports', 1.0): 6,\n",
              " ('buuut', 1.0): 1,\n",
              " ('oh', 1.0): 44,\n",
              " ('looking', 1.0): 45,\n",
              " ('forward', 1.0): 20,\n",
              " ('visiting', 1.0): 2,\n",
              " ('next', 1.0): 37,\n",
              " ('letsgetmessy', 1.0): 1,\n",
              " ('jo', 1.0): 1,\n",
              " ('if', 1.0): 142,\n",
              " ('makes', 1.0): 12,\n",
              " ('feel', 1.0): 22,\n",
              " ('better', 1.0): 40,\n",
              " ('never', 1.0): 31,\n",
              " ('nor', 1.0): 1,\n",
              " ('anyone', 1.0): 7,\n",
              " ('kpop', 1.0): 1,\n",
              " ('flesh', 1.0): 1,\n",
              " ('good', 1.0): 189,\n",
              " ('girl', 1.0): 23,\n",
              " ('best', 1.0): 48,\n",
              " ('wishes', 1.0): 3,\n",
              " ('reason', 1.0): 8,\n",
              " ('epic', 1.0): 1,\n",
              " ('soundtrack', 1.0): 1,\n",
              " ('shout', 1.0): 9,\n",
              " ('added', 1.0): 8,\n",
              " ('video', 1.0): 25,\n",
              " ('playlist', 1.0): 5,\n",
              " ('would', 1.0): 70,\n",
              " ('dear', 1.0): 15,\n",
              " ('jordan', 1.0): 1,\n",
              " ('okay', 1.0): 31,\n",
              " ('fake', 1.0): 1,\n",
              " ('gameplays', 1.0): 1,\n",
              " (';)', 1.0): 22,\n",
              " ('haha', 1.0): 44,\n",
              " ('im', 1.0): 38,\n",
              " ('kidding', 1.0): 4,\n",
              " ('do', 1.0): 120,\n",
              " ('stuff', 1.0): 11,\n",
              " ('exactly', 1.0): 5,\n",
              " ('product', 1.0): 3,\n",
              " ('line', 1.0): 3,\n",
              " ('etsy', 1.0): 1,\n",
              " ('shop', 1.0): 7,\n",
              " ('check', 1.0): 35,\n",
              " ('vacation', 1.0): 5,\n",
              " ('going', 1.0): 52,\n",
              " ('they', 1.0): 48,\n",
              " ('rechargeable', 1.0): 1,\n",
              " ('normally', 1.0): 2,\n",
              " ('comes', 1.0): 5,\n",
              " ('charger', 1.0): 2,\n",
              " ('buy', 1.0): 8,\n",
              " (\"she's\", 1.0): 7,\n",
              " ('asleep', 1.0): 7,\n",
              " ('no', 1.0): 136,\n",
              " ('talk', 1.0): 19,\n",
              " ('sooo', 1.0): 6,\n",
              " ('someone', 1.0): 29,\n",
              " ('text', 1.0): 11,\n",
              " ('yes', 1.0): 58,\n",
              " ('bet', 1.0): 5,\n",
              " (\"he'll\", 1.0): 2,\n",
              " ('fit', 1.0): 2,\n",
              " ('after', 1.0): 17,\n",
              " ('hearing', 1.0): 1,\n",
              " ('her', 1.0): 35,\n",
              " ('speech', 1.0): 1,\n",
              " ('pity', 1.0): 2,\n",
              " ('green', 1.0): 2,\n",
              " ('gardens', 1.0): 1,\n",
              " ('midnight', 1.0): 1,\n",
              " ('sun', 1.0): 6,\n",
              " ('beautiful', 1.0): 40,\n",
              " ('canals', 1.0): 1,\n",
              " ('dasvidaniya', 1.0): 1,\n",
              " ('till', 1.0): 16,\n",
              " ('visit', 1.0): 22,\n",
              " ('scouting', 1.0): 1,\n",
              " ('sg', 1.0): 1,\n",
              " ('future', 1.0): 9,\n",
              " ('wlan', 1.0): 1,\n",
              " ('pros', 1.0): 1,\n",
              " ('conference', 1.0): 1,\n",
              " ('here', 1.0): 89,\n",
              " ('asia', 1.0): 1,\n",
              " ('change', 1.0): 9,\n",
              " ('lollipop', 1.0): 1,\n",
              " ('üç≠', 1.0): 1,\n",
              " ('nez', 1.0): 1,\n",
              " ('agnezmo', 1.0): 1,\n",
              " ('oley', 1.0): 1,\n",
              " ('mama', 1.0): 1,\n",
              " ('only', 1.0): 47,\n",
              " ('why', 1.0): 25,\n",
              " ('stand', 1.0): 3,\n",
              " ('stronger', 1.0): 1,\n",
              " ('up', 1.0): 114,\n",
              " ('god', 1.0): 14,\n",
              " ('misty', 1.0): 1,\n",
              " ('baby', 1.0): 17,\n",
              " ('cute', 1.0): 21,\n",
              " ('woohoo', 1.0): 3,\n",
              " (\"can't\", 1.0): 31,\n",
              " ('wait', 1.0): 32,\n",
              " ('signed', 1.0): 3,\n",
              " ('yet', 1.0): 12,\n",
              " ('or', 1.0): 45,\n",
              " ('still', 1.0): 37,\n",
              " ('thinking', 1.0): 8,\n",
              " ('about', 1.0): 95,\n",
              " ('mka', 1.0): 5,\n",
              " ('liam', 1.0): 5,\n",
              " ('access', 1.0): 3,\n",
              " ('most', 1.0): 25,\n",
              " ('welcome', 1.0): 51,\n",
              " ('stats', 1.0): 51,\n",
              " ('day', 1.0): 157,\n",
              " ('arrived', 1.0): 55,\n",
              " ('1', 1.0): 60,\n",
              " ('follower', 1.0): 40,\n",
              " ('unfollowers', 1.0): 51,\n",
              " ('via', 1.0): 60,\n",
              " (\"shouldn't\", 1.0): 2,\n",
              " ('surprised', 1.0): 2,\n",
              " ('figure', 1.0): 3,\n",
              " ('happybirthdayemilybett', 1.0): 1,\n",
              " ('wishing', 1.0): 12,\n",
              " ('all', 1.0): 159,\n",
              " ('sweet', 1.0): 16,\n",
              " ('talented', 1.0): 4,\n",
              " ('2', 1.0): 41,\n",
              " ('plans', 1.0): 5,\n",
              " ('down', 1.0): 23,\n",
              " ('drain', 1.0): 1,\n",
              " ('gotta', 1.0): 4,\n",
              " ('timezones', 1.0): 1,\n",
              " ('parents', 1.0): 3,\n",
              " ('proud', 1.0): 11,\n",
              " ('least', 1.0): 14,\n",
              " ('maybe', 1.0): 17,\n",
              " ('sometimes', 1.0): 9,\n",
              " ('because', 1.0): 28,\n",
              " ('grades', 1.0): 2,\n",
              " ('al', 1.0): 3,\n",
              " ('grande', 1.0): 3,\n",
              " ('manila_bro', 1.0): 1,\n",
              " ('chosen', 1.0): 1,\n",
              " ('let', 1.0): 48,\n",
              " (\"you're\", 1.0): 74,\n",
              " ('around', 1.0): 14,\n",
              " ('..', 1.0): 100,\n",
              " ('side', 1.0): 12,\n",
              " ('world', 1.0): 23,\n",
              " ('eh', 1.0): 2,\n",
              " ('too', 1.0): 108,\n",
              " ('take', 1.0): 25,\n",
              " ('care', 1.0): 9,\n",
              " ('finally', 1.0): 13,\n",
              " ('fucking', 1.0): 9,\n",
              " ('weekend', 1.0): 61,\n",
              " ('real', 1.0): 18,\n",
              " ('x45', 1.0): 1,\n",
              " ('joined', 1.0): 6,\n",
              " ('hushedcallwithfraydoe', 1.0): 1,\n",
              " ('gift', 1.0): 4,\n",
              " ('from', 1.0): 83,\n",
              " ('yeahhh', 1.0): 1,\n",
              " ('make', 1.0): 45,\n",
              " ('hushedpinwithsammy', 1.0): 2,\n",
              " ('event', 1.0): 6,\n",
              " ('might', 1.0): 21,\n",
              " ('luv', 1.0): 4,\n",
              " ('really', 1.0): 66,\n",
              " ('appreciate', 1.0): 17,\n",
              " ('share', 1.0): 19,\n",
              " ('wow', 1.0): 14,\n",
              " ('that', 1.0): 222,\n",
              " ('tom', 1.0): 5,\n",
              " ('gym', 1.0): 3,\n",
              " ('monday', 1.0): 7,\n",
              " ('likes', 1.0): 3,\n",
              " ('invite', 1.0): 14,\n",
              " ('join', 1.0): 12,\n",
              " ('scope', 1.0): 5,\n",
              " ('influencer', 1.0): 5,\n",
              " ('those', 1.0): 21,\n",
              " ('friends', 1.0): 19,\n",
              " ('themselves', 1.0): 3,\n",
              " ('nudes', 1.0): 1,\n",
              " ('sleep', 1.0): 32,\n",
              " ('birthday', 1.0): 51,\n",
              " ('want', 1.0): 54,\n",
              " ('t-shirts', 1.0): 1,\n",
              " ('cool', 1.0): 28,\n",
              " ('haw', 1.0): 1,\n",
              " ('phela', 1.0): 1,\n",
              " ('mom', 1.0): 6,\n",
              " ('obviously', 1.0): 1,\n",
              " ('him', 1.0): 31,\n",
              " ('prince', 1.0): 1,\n",
              " ('charming', 1.0): 1,\n",
              " ('stage', 1.0): 2,\n",
              " ('luck', 1.0): 26,\n",
              " ('tylers', 1.0): 1,\n",
              " ('hipster', 1.0): 1,\n",
              " ('glasses', 1.0): 1,\n",
              " ('marty', 1.0): 2,\n",
              " ('glad', 1.0): 41,\n",
              " ('joining', 1.0): 3,\n",
              " ('again', 1.0): 43,\n",
              " ('done', 1.0): 40,\n",
              " ('its', 1.0): 53,\n",
              " ('afternoon', 1.0): 7,\n",
              " ('lets', 1.0): 8,\n",
              " ('read', 1.0): 18,\n",
              " ('kahfi', 1.0): 1,\n",
              " ('before', 1.0): 20,\n",
              " ('finish', 1.0): 2,\n",
              " ('ohmyg', 1.0): 1,\n",
              " ('yaya', 1.0): 3,\n",
              " ('dub', 1.0): 1,\n",
              " ('doing', 1.0): 24,\n",
              " ('stalk', 1.0): 1,\n",
              " ('ig', 1.0): 3,\n",
              " ('gondooo', 1.0): 1,\n",
              " ('moo', 1.0): 2,\n",
              " ('tologooo', 1.0): 1,\n",
              " ('become', 1.0): 5,\n",
              " ('details', 1.0): 6,\n",
              " ('zzz', 1.0): 1,\n",
              " ('xx', 1.0): 33,\n",
              " ('physiotherapy', 1.0): 1,\n",
              " ('hashtag', 1.0): 3,\n",
              " ('custom', 1.0): 1,\n",
              " ('üí™', 1.0): 1,\n",
              " ('monica', 1.0): 1,\n",
              " ('miss', 1.0): 13,\n",
              " ('sounds', 1.0): 16,\n",
              " ('morning', 1.0): 67,\n",
              " (\"that's\", 1.0): 49,\n",
              " ('takes', 1.0): 3,\n",
              " ('x43', 1.0): 1,\n",
              " ('definitely', 1.0): 19,\n",
              " ('try', 1.0): 19,\n",
              " ('tonight', 1.0): 15,\n",
              " ('then', 1.0): 34,\n",
              " ('took', 1.0): 7,\n",
              " ('advice', 1.0): 6,\n",
              " ('treviso', 1.0): 1,\n",
              " ('concert', 1.0): 23,\n",
              " ('city', 1.0): 26,\n",
              " ('country', 1.0): 19,\n",
              " (\"i'll\", 1.0): 73,\n",
              " ('start', 1.0): 41,\n",
              " ('fine', 1.0): 7,\n",
              " ('gorgeous', 1.0): 9,\n",
              " ('friend', 1.0): 21,\n",
              " ('xo', 1.0): 2,\n",
              " ('oven', 1.0): 2,\n",
              " ('roasted', 1.0): 1,\n",
              " ('garlic', 1.0): 1,\n",
              " ('olive', 1.0): 1,\n",
              " ('oil', 1.0): 4,\n",
              " ('dried', 1.0): 2,\n",
              " ('tomatoes', 1.0): 1,\n",
              " ('some', 1.0): 81,\n",
              " ('basil', 1.0): 1,\n",
              " ('century', 1.0): 1,\n",
              " ('tuna', 1.0): 1,\n",
              " ('right', 1.0): 37,\n",
              " ('back', 1.0): 73,\n",
              " ('atchya', 1.0): 1,\n",
              " (\"doesn't\", 1.0): 15,\n",
              " ('even', 1.0): 24,\n",
              " ('almost', 1.0): 8,\n",
              " ('chance', 1.0): 3,\n",
              " ('cheers', 1.0): 17,\n",
              " ('po', 1.0): 3,\n",
              " ('ice', 1.0): 6,\n",
              " ('cream', 1.0): 6,\n",
              " ('agree', 1.0): 11,\n",
              " ('100', 1.0): 6,\n",
              " ('hehehehe', 1.0): 2,\n",
              " ('thats', 1.0): 10,\n",
              " ('point', 1.0): 7,\n",
              " ('stay', 1.0): 19,\n",
              " ('home', 1.0): 20,\n",
              " ('soon', 1.0): 38,\n",
              " ('promise', 1.0): 4,\n",
              " ('web', 1.0): 4,\n",
              " ('whatsapp', 1.0): 3,\n",
              " ('volta', 1.0): 1,\n",
              " ('funcionar', 1.0): 1,\n",
              " ('com', 1.0): 2,\n",
              " ('iphone', 1.0): 7,\n",
              " ('jailbroken', 1.0): 1,\n",
              " ('plan', 1.0): 10,\n",
              " ('watching', 1.0): 11,\n",
              " ('later', 1.0): 11,\n",
              " ('34', 1.0): 3,\n",
              " ('mins', 1.0): 6,\n",
              " ('leia', 1.0): 1,\n",
              " ('appears', 1.0): 2,\n",
              " ('hologram', 1.0): 1,\n",
              " ('r2d2', 1.0): 1,\n",
              " ('w', 1.0): 16,\n",
              " ('message', 1.0): 7,\n",
              " ('obi', 1.0): 1,\n",
              " ('wan', 1.0): 1,\n",
              " ('he', 1.0): 46,\n",
              " ('sits', 1.0): 2,\n",
              " ('luke', 1.0): 4,\n",
              " ('inter', 1.0): 1,\n",
              " ('3', 1.0): 25,\n",
              " ('ucl', 1.0): 1,\n",
              " ('arsenal', 1.0): 2,\n",
              " ('small', 1.0): 1,\n",
              " ('team', 1.0): 24,\n",
              " ('passing', 1.0): 1,\n",
              " ('üöÇ', 1.0): 1,\n",
              " ('dewsbury', 1.0): 2,\n",
              " ('railway', 1.0): 1,\n",
              " ('station', 1.0): 4,\n",
              " ('dew', 1.0): 1,\n",
              " ('west', 1.0): 1,\n",
              " ('yorkshire', 1.0): 2,\n",
              " ('430', 1.0): 1,\n",
              " ('smh', 1.0): 2,\n",
              " (\"it's\", 1.0): 117,\n",
              " ('9:25', 1.0): 1,\n",
              " ('live', 1.0): 16,\n",
              " ('strange', 1.0): 3,\n",
              " ('imagine', 1.0): 4,\n",
              " ('what', 1.0): 88,\n",
              " ('megan', 1.0): 1,\n",
              " ('masaantoday', 1.0): 4,\n",
              " ('a4', 1.0): 3,\n",
              " ('shweta', 1.0): 1,\n",
              " ('tripathi', 1.0): 1,\n",
              " ('5', 1.0): 15,\n",
              " ('over', 1.0): 25,\n",
              " ('20', 1.0): 5,\n",
              " ('kurtas', 1.0): 1,\n",
              " ('half', 1.0): 6,\n",
              " ('number', 1.0): 11,\n",
              " ('wsalelove', 1.0): 14,\n",
              " ('ah', 1.0): 12,\n",
              " ('larry', 1.0): 3,\n",
              " ('anyway', 1.0): 14,\n",
              " ('kinda', 1.0): 12,\n",
              " ('goood', 1.0): 1,\n",
              " ('life', 1.0): 36,\n",
              " ('enn', 1.0): 1,\n",
              " ('surely', 1.0): 2,\n",
              " ('could', 1.0): 25,\n",
              " ('warmup', 1.0): 1,\n",
              " ('coming', 1.0): 16,\n",
              " ('15th', 1.0): 2,\n",
              " ('bath', 1.0): 6,\n",
              " ('dum', 1.0): 2,\n",
              " ('andar', 1.0): 1,\n",
              " ('ram', 1.0): 1,\n",
              " ('sampath', 1.0): 1,\n",
              " ('sona', 1.0): 1,\n",
              " ('mohapatra', 1.0): 1,\n",
              " ('samantha', 1.0): 1,\n",
              " ('edwards', 1.0): 1,\n",
              " ('mein', 1.0): 1,\n",
              " ('tulane', 1.0): 1,\n",
              " ('razi', 1.0): 2,\n",
              " ('wah', 1.0): 2,\n",
              " ('josh', 1.0): 1,\n",
              " ('always', 1.0): 48,\n",
              " ('smile', 1.0): 30,\n",
              " ('picture', 1.0): 5,\n",
              " ('16.20', 1.0): 1,\n",
              " ('timing', 1.0): 4,\n",
              " ('giveitup', 1.0): 1,\n",
              " ('given', 1.0): 3,\n",
              " ('gas', 1.0): 1,\n",
              " ('subsidy', 1.0): 1,\n",
              " ('initiative', 1.0): 1,\n",
              " ('proposed', 1.0): 1,\n",
              " ('feeling', 1.0): 9,\n",
              " ('delighted', 1.0): 3,\n",
              " ('having', 1.0): 23,\n",
              " ('missed', 1.0): 2,\n",
              " ('yesterday', 1.0): 4,\n",
              " ('x42', 1.0): 1,\n",
              " ('lmaoo', 1.0): 2,\n",
              " ('songs', 1.0): 5,\n",
              " ('ever', 1.0): 19,\n",
              " ('shall', 1.0): 5,\n",
              " ('own', 1.0): 3,\n",
              " ('little', 1.0): 29,\n",
              " ('throwback', 1.0): 3,\n",
              " ('outlying', 1.0): 1,\n",
              " ('islands', 1.0): 1,\n",
              " ('such', 1.0): 17,\n",
              " ('cheung', 1.0): 1,\n",
              " ('chau', 1.0): 1,\n",
              " ('mui', 1.0): 1,\n",
              " ('wo', 1.0): 1,\n",
              " ('totally', 1.0): 4,\n",
              " ('different', 1.0): 7,\n",
              " ('kfckitchentours', 1.0): 2,\n",
              " ('kitchen', 1.0): 3,\n",
              " ('clean', 1.0): 1,\n",
              " (\"i'm\", 1.0): 140,\n",
              " ('amazed', 1.0): 1,\n",
              " ('cusp', 1.0): 1,\n",
              " ('testing', 1.0): 2,\n",
              " ('waters', 1.0): 1,\n",
              " ('yours', 1.0): 9,\n",
              " ('rewarding', 1.0): 1,\n",
              " ('arummzz', 1.0): 2,\n",
              " (\"let's\", 1.0): 18,\n",
              " ('drive', 1.0): 4,\n",
              " ('traveling', 1.0): 4,\n",
              " ('traveler', 1.0): 3,\n",
              " ('yogyakarta', 1.0): 3,\n",
              " ('jeep', 1.0): 3,\n",
              " ('indonesia', 1.0): 3,\n",
              " ('instamood', 1.0): 3,\n",
              " ('wanna', 1.0): 23,\n",
              " ('skype', 1.0): 3,\n",
              " ('may', 1.0): 16,\n",
              " ('look', 1.0): 37,\n",
              " ('nice', 1.0): 70,\n",
              " ('friendly', 1.0): 1,\n",
              " ('them', 1.0): 48,\n",
              " ('pretend', 1.0): 2,\n",
              " ('where', 1.0): 20,\n",
              " ('film', 1.0): 4,\n",
              " ('congratulations', 1.0): 8,\n",
              " ('winner', 1.0): 3,\n",
              " ('cheesydelights', 1.0): 1,\n",
              " ('contest', 1.0): 5,\n",
              " ('address', 1.0): 8,\n",
              " ('guys', 1.0): 40,\n",
              " ('seeing', 1.0): 14,\n",
              " ('marketing', 1.0): 2,\n",
              " ('24/7', 1.0): 1,\n",
              " ('14', 1.0): 1,\n",
              " ('hours', 1.0): 15,\n",
              " ('leave', 1.0): 8,\n",
              " ('without', 1.0): 9,\n",
              " ('delays', 1.0): 1,\n",
              " ('actually', 1.0): 13,\n",
              " ('very', 1.0): 63,\n",
              " ('easy', 1.0): 7,\n",
              " ('guess', 1.0): 8,\n",
              " ('train', 1.0): 4,\n",
              " ('wd', 1.0): 1,\n",
              " ('hour', 1.0): 9,\n",
              " ('shifting', 1.0): 1,\n",
              " ('engine', 1.0): 1,\n",
              " ('etc', 1.0): 2,\n",
              " ('sunburn', 1.0): 1,\n",
              " ('peeling', 1.0): 1,\n",
              " ('blog', 1.0): 24,\n",
              " ('huge', 1.0): 9,\n",
              " ('warm', 1.0): 4,\n",
              " ('‚òÜ', 1.0): 3,\n",
              " ('complete', 1.0): 4,\n",
              " ('triangle', 1.0): 2,\n",
              " ('northern', 1.0): 1,\n",
              " ('ireland', 1.0): 2,\n",
              " ('sights', 1.0): 1,\n",
              " ('smthng', 1.0): 2,\n",
              " ('fr', 1.0): 3,\n",
              " ('hug', 1.0): 2,\n",
              " ('xoxo', 1.0): 3,\n",
              " ('uu', 1.0): 1,\n",
              " ('jaann', 1.0): 1,\n",
              " ('topnewfollowers', 1.0): 2,\n",
              " ('connect', 1.0): 6,\n",
              " ('wonderful', 1.0): 16,\n",
              " ('made', 1.0): 38,\n",
              " ('fluffy', 1.0): 1,\n",
              " ('inside', 1.0): 7,\n",
              " ('pirouette', 1.0): 1,\n",
              " ('moose', 1.0): 1,\n",
              " ('trip', 1.0): 11,\n",
              " ('philly', 1.0): 1,\n",
              " ('december', 1.0): 2,\n",
              " (\"i'd\", 1.0): 13,\n",
              " ('dude', 1.0): 5,\n",
              " ('x41', 1.0): 1,\n",
              " ('question', 1.0): 11,\n",
              " ('flawed', 1.0): 1,\n",
              " ('pain', 1.0): 7,\n",
              " ('negate', 1.0): 1,\n",
              " ('strength', 1.0): 2,\n",
              " ('went', 1.0): 10,\n",
              " ('solo', 1.0): 4,\n",
              " ('moves', 1.0): 1,\n",
              " (\"weren't\", 1.0): 3,\n",
              " ('fav', 1.0): 11,\n",
              " ('nirvana', 1.0): 1,\n",
              " ('song', 1.0): 11,\n",
              " ('smells', 1.0): 1,\n",
              " ('teen', 1.0): 2,\n",
              " ('spirit', 1.0): 1,\n",
              " ('rip', 1.0): 3,\n",
              " ('amy', 1.0): 3,\n",
              " ('winehouse', 1.0): 1,\n",
              " ('did', 1.0): 32,\n",
              " ('couple', 1.0): 4,\n",
              " ('tomhiddleston', 1.0): 1,\n",
              " ('elizabetholsen', 1.0): 1,\n",
              " ('yaytheylookgreat', 1.0): 1,\n",
              " ('goodnight', 1.0): 18,\n",
              " ('vid', 1.0): 6,\n",
              " ('wake', 1.0): 4,\n",
              " ('gonna', 1.0): 16,\n",
              " ('shoot', 1.0): 3,\n",
              " ('itty', 1.0): 2,\n",
              " ('bitty', 1.0): 2,\n",
              " ('teenie', 1.0): 2,\n",
              " ('bikini', 1.0): 2,\n",
              " ('much', 1.0): 73,\n",
              " ('4th', 1.0): 4,\n",
              " ('gets', 1.0): 5,\n",
              " ('together', 1.0): 6,\n",
              " ('ending', 1.0): 1,\n",
              " ('xfiles', 1.0): 1,\n",
              " ('content', 1.0): 3,\n",
              " ('rain', 1.0): 16,\n",
              " ('fabulous', 1.0): 4,\n",
              " ('fantastic', 1.0): 8,\n",
              " ('work', 1.0): 52,\n",
              " ('‚ô°', 1.0): 12,\n",
              " ('jb', 1.0): 1,\n",
              " ('forever', 1.0): 5,\n",
              " ('belieber', 1.0): 2,\n",
              " ('hear', 1.0): 23,\n",
              " ('nighty', 1.0): 1,\n",
              " ('bugs', 1.0): 1,\n",
              " ('bite', 1.0): 1,\n",
              " ('bracelet', 1.0): 2,\n",
              " ('idea', 1.0): 18,\n",
              " ('foundry', 1.0): 1,\n",
              " ('game', 1.0): 17,\n",
              " ('sense', 1.0): 6,\n",
              " (\"didn't\", 1.0): 16,\n",
              " ('pic', 1.0): 14,\n",
              " ('effing', 1.0): 1,\n",
              " ('phone', 1.0): 14,\n",
              " ('woot', 1.0): 2,\n",
              " ('derek', 1.0): 1,\n",
              " ('using', 1.0): 7,\n",
              " ('parkshare', 1.0): 1,\n",
              " ('gloucestershire', 1.0): 1,\n",
              " ('aaaahhh', 1.0): 1,\n",
              " ('man', 1.0): 15,\n",
              " ('traffic', 1.0): 2,\n",
              " ('stress', 1.0): 4,\n",
              " ('reliever', 1.0): 1,\n",
              " (\"how're\", 1.0): 1,\n",
              " ('arbeloa', 1.0): 1,\n",
              " ('turning', 1.0): 3,\n",
              " ('17', 1.0): 2,\n",
              " ('omg', 1.0): 13,\n",
              " ('difference', 1.0): 1,\n",
              " ('say', 1.0): 30,\n",
              " ('europe', 1.0): 1,\n",
              " ('rise', 1.0): 1,\n",
              " ('find', 1.0): 16,\n",
              " ('hard', 1.0): 9,\n",
              " ('believe', 1.0): 7,\n",
              " ('uncountable', 1.0): 1,\n",
              " ('coz', 1.0): 2,\n",
              " ('unlimited', 1.0): 1,\n",
              " ('course', 1.0): 11,\n",
              " ('teampositive', 1.0): 1,\n",
              " ('aldub', 1.0): 2,\n",
              " ('‚òï', 1.0): 3,\n",
              " ('rita', 1.0): 2,\n",
              " ('further', 1.0): 2,\n",
              " ('info', 1.0): 10,\n",
              " (\"we'd\", 1.0): 4,\n",
              " ('way', 1.0): 33,\n",
              " ('boy', 1.0): 10,\n",
              " ('gifts', 1.0): 1,\n",
              " ('x40', 1.0): 1,\n",
              " ('true', 1.0): 19,\n",
              " ('sethi', 1.0): 2,\n",
              " ('high', 1.0): 6,\n",
              " ('exe', 1.0): 1,\n",
              " ('skeem', 1.0): 1,\n",
              " ('saam', 1.0): 1,\n",
              " ('people', 1.0): 42,\n",
              " ('polite', 1.0): 2,\n",
              " ('izzat', 1.0): 1,\n",
              " ('wese', 1.0): 1,\n",
              " ('does', 1.0): 22,\n",
              " ('trust', 1.0): 5,\n",
              " ('khawateen', 1.0): 1,\n",
              " ('k', 1.0): 8,\n",
              " ('sath', 1.0): 2,\n",
              " ('mana', 1.0): 1,\n",
              " ('kar', 1.0): 1,\n",
              " ('deya', 1.0): 1,\n",
              " ('evening', 1.0): 2,\n",
              " ('sorted', 1.0): 4,\n",
              " ('smart', 1.0): 5,\n",
              " ('hair', 1.0): 6,\n",
              " ('tbh', 1.0): 5,\n",
              " ('jacob', 1.0): 2,\n",
              " ('m', 1.0): 10,\n",
              " ('g', 1.0): 7,\n",
              " ('upgrade', 1.0): 1,\n",
              " ('tee', 1.0): 2,\n",
              " ('family', 1.0): 13,\n",
              " ('reading', 1.0): 9,\n",
              " ('talking', 1.0): 13,\n",
              " ('person', 1.0): 10,\n",
              " ('two', 1.0): 15,\n",
              " ('conversations', 1.0): 2,\n",
              " ('should', 1.0): 27,\n",
              " ('online', 1.0): 4,\n",
              " ('mclaren', 1.0): 1,\n",
              " ('fridayfeeling', 1.0): 5,\n",
              " ('tgif', 1.0): 8,\n",
              " ('square', 1.0): 1,\n",
              " ('enix', 1.0): 1,\n",
              " ('bissmillah', 1.0): 1,\n",
              " ('ya', 1.0): 19,\n",
              " ('allah', 1.0): 3,\n",
              " (\"we're\", 1.0): 25,\n",
              " ('training', 1.0): 3,\n",
              " ('socent', 1.0): 1,\n",
              " ('startups', 1.0): 1,\n",
              " ('drop', 1.0): 8,\n",
              " ('youre', 1.0): 3,\n",
              " ('arnd', 1.0): 1,\n",
              " ('town', 1.0): 2,\n",
              " ('basically', 1.0): 4,\n",
              " ('piss', 1.0): 1,\n",
              " ('cup', 1.0): 4,\n",
              " ('test', 1.0): 4,\n",
              " ('also', 1.0): 28,\n",
              " ('terrible', 1.0): 2,\n",
              " ('complicated', 1.0): 1,\n",
              " ('discussions', 1.0): 1,\n",
              " ('snapchat', 1.0): 31,\n",
              " ('lynettelowe', 1.0): 1,\n",
              " ('kikmenow', 1.0): 2,\n",
              " ('snapme', 1.0): 1,\n",
              " ('hot', 1.0): 20,\n",
              " ('amazon', 1.0): 1,\n",
              " ('kikmeguys', 1.0): 2,\n",
              " ('shift', 1.0): 3,\n",
              " ('definately', 1.0): 1,\n",
              " ('growing', 1.0): 4,\n",
              " ('sport', 1.0): 2,\n",
              " ('rt', 1.0): 4,\n",
              " ('rakyat', 1.0): 1,\n",
              " ('writing', 1.0): 5,\n",
              " ('since', 1.0): 11,\n",
              " ('mentioned', 1.0): 3,\n",
              " ('fly', 1.0): 4,\n",
              " ('fishing', 1.0): 1,\n",
              " ('other', 1.0): 13,\n",
              " ('getting', 1.0): 24,\n",
              " ('follows', 1.0): 4,\n",
              " ('promoted', 1.0): 1,\n",
              " ('posts', 1.0): 1,\n",
              " ('cyber', 1.0): 1,\n",
              " ('stalked', 1.0): 1,\n",
              " ('ourdaughtersourpride', 1.0): 3,\n",
              " ('mypapamypride', 1.0): 2,\n",
              " ('papa', 1.0): 1,\n",
              " ('coach', 1.0): 2,\n",
              " ('positive', 1.0): 3,\n",
              " ('kha', 1.0): 1,\n",
              " ('mention', 1.0): 12,\n",
              " ('atleast', 1.0): 2,\n",
              " ('x39', 1.0): 1,\n",
              " ('mango', 1.0): 1,\n",
              " (\"lassi's\", 1.0): 1,\n",
              " (\"monty's\", 1.0): 1,\n",
              " ('marvellous', 1.0): 1,\n",
              " ('though', 1.0): 16,\n",
              " ('suspect', 1.0): 2,\n",
              " ('meant', 1.0): 2,\n",
              " ('24', 1.0): 3,\n",
              " ('hrs', 1.0): 1,\n",
              " ('touch', 1.0): 7,\n",
              " ('kepler', 1.0): 3,\n",
              " ('452b', 1.0): 4,\n",
              " ('chalna', 1.0): 1,\n",
              " ('hai', 1.0): 7,\n",
              " ('thankyou', 1.0): 12,\n",
              " ('hazel', 1.0): 1,\n",
              " ('food', 1.0): 6,\n",
              " ('market', 1.0): 3,\n",
              " ('brooklyn', 1.0): 1,\n",
              " ('pta', 1.0): 2,\n",
              " ('awake', 1.0): 7,\n",
              " ('okayy', 1.0): 2,\n",
              " ('awww', 1.0): 12,\n",
              " ('ha', 1.0): 18,\n",
              " ('surprise', 1.0): 7,\n",
              " ('doc', 1.0): 1,\n",
              " ('splendid', 1.0): 1,\n",
              " ('spam', 1.0): 1,\n",
              " ('folder', 1.0): 1,\n",
              " ('won', 1.0): 6,\n",
              " ('amount', 1.0): 1,\n",
              " ('travel', 1.0): 11,\n",
              " ('nigeria', 1.0): 1,\n",
              " ('claim', 1.0): 1,\n",
              " ('rted', 1.0): 1,\n",
              " ('legs', 1.0): 2,\n",
              " ('hurt', 1.0): 3,\n",
              " ('bad', 1.0): 14,\n",
              " ('mine', 1.0): 11,\n",
              " ('saturday', 1.0): 5,\n",
              " ('thaaanks', 1.0): 1,\n",
              " ('puhon', 1.0): 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H√†m l·∫•y ra t·∫ßn su·∫•t xu·∫•t hi·ªán l√† value trong `freq` d·ª±a v√†o key (word, label)\n",
        "def lookup(freqs, word, label):\n",
        "    '''\n",
        "    Args:\n",
        "        freqs: a dictionary with the frequency of each pair\n",
        "        word: the word to look up\n",
        "        label: the label corresponding to the word\n",
        "    Output:\n",
        "        count: the number of times the word with its corresponding label appears.\n",
        "    '''\n",
        "    count = 0\n",
        "\n",
        "    pair = (word, label)\n",
        "    if pair in freqs:\n",
        "        count = freqs[pair]\n",
        "\n",
        "    return count\n",
        "\n",
        "lookup(freqs, \"just\", 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQo2dcyzjgvo",
        "outputId": "17dd3896-fc40-4c00-eac8-ef7835d10774"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Algorithm"
      ],
      "metadata": {
        "id": "5VT2b8D8jpmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_prior_prob(train_y):\n",
        "    # T√≠nh D, D_pos, D_neg d·ª±a v√†o x_train\n",
        "    ### START CODE HERE\n",
        "    # T√≠nh D, s·ªë l∆∞·ª£ng c√°c sample trong training\n",
        "    D = len(train_y)\n",
        "\n",
        "    # T√≠nh D_pos, s·ªë l∆∞·ª£ng c√°c positive sample trong training\n",
        "    D_pos = len(list(filter(lambda x: x == 1, train_y)))\n",
        "\n",
        "    # T√≠nh D_neg, s·ªë l∆∞·ª£ng c√°c negative sample trong training\n",
        "    D_neg = len(list(filter(lambda x: x == 0, train_y)))\n",
        "\n",
        "    ### END CODE HERE\n",
        "    # T√≠nh x√°c su·∫•t ti√™n nghi·ªám cho c√°c class 0 v√† 1\n",
        "    p_prior = {0:(D_neg/D), 1:(D_pos/D)}\n",
        "    return p_prior"
      ],
      "metadata": {
        "id": "IiddfIDkjpGx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_prior_prob(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thHBiF0cjyY9",
        "outputId": "d244927b-cf19-48a4-fbfc-47503c309bda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5, 1: 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_likelihood(freqs):\n",
        "    # T√≠nh x√°c su·∫•t likelihood c·ªßa m·ªói t·ª´ trong b·ªô t·ª´ ƒëi·ªÉn\n",
        "\n",
        "    ### START CODE HERE\n",
        "    # T√≠nh V c√°c t·ª´ duy nh·∫•t xu·∫•t hi·ªán trong t·∫≠p train\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # T√≠nh N_pos: s·ªë l∆∞·ª£ng t·ª´ trong positive samples v√† N_neg: s·ªë t·ª´ trong negative sample\n",
        "    N_pos = N_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # N·∫øu nh∆∞ class: 1 tƒÉng N_pos th√™m s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa pair trong freqs\n",
        "        if pair[1] > 0:\n",
        "            N_pos += freqs[pair]\n",
        "\n",
        "        # N·∫øu nh∆∞ class: 0 tƒÉng N_neg th√™m s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa pair trong freqs\n",
        "        else:\n",
        "            N_neg += freqs[pair]\n",
        "\n",
        "    print(f'V: {V}, N_pos: {N_pos}, N_neg: {N_neg}')\n",
        "\n",
        "    # T√≠nh likelihood cho m·ªói t·ª´ trong b·ªô t·ª´ ƒëi·ªÉn\n",
        "    p_likelihood = {}\n",
        "    for word in vocab:\n",
        "        # L·∫•y t·∫ßn xu·∫•t xu·∫•t hi·ªán c·ªßa m·ªói t·ª´ l√† positive ho·∫∑c negative\n",
        "        freq_pos = lookup(freqs, word, 1)\n",
        "        freq_neg = lookup(freqs, word, 0)\n",
        "\n",
        "        # T√≠nh x√°c su·∫•t likelihood c·ªßa m·ªói t·ª´ v·ªõi class positive v√† negative\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        # L∆∞u v√†o p_likelihood dictionary\n",
        "        p_likelihood[word] = {0:p_w_neg, 1:p_w_pos}\n",
        "    # END CODE HERE\n",
        "\n",
        "    return p_likelihood"
      ],
      "metadata": {
        "id": "2zQYlM-Vj7oU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(train_x, train_y):\n",
        "    ''' Hu·∫•n luy·ªán thu·∫≠t to√°n Naive Bayes\n",
        "    Args:\n",
        "        train_x: Danh s√°ch c√°c c√¢u\n",
        "        train_y: Danh s√°ch c√°c nh√£n t∆∞∆°ng ·ª©ng (0 ho·∫∑c 1)\n",
        "    Output:\n",
        "        p_prior: the prior probability (X√°c su·∫• ti√™n nghi·ªám)\n",
        "        p_likelihood: the maximum likelihood of the probability.\n",
        "    '''\n",
        "    # X√¢y d·ª±ng t·ª´ ƒëi·ªÉn t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa t·ª´ v√† nh√£n t∆∞∆°ng ·ª©ng\n",
        "    freqs = count_freq_words(train_x, train_y)\n",
        "\n",
        "    # T√≠nh x√°c su·∫•t ti√™n nghi·ªám\n",
        "    p_prior = compute_prior_prob(train_y)\n",
        "\n",
        "    # T√≠nh x√°c su·∫•t likelihood\n",
        "    p_likelihood = compute_likelihood(freqs)\n",
        "\n",
        "    return p_prior, p_likelihood"
      ],
      "metadata": {
        "id": "d9rrppu2j_JF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(sentence, p_prior, p_likelihood):\n",
        "    '''\n",
        "    Args:\n",
        "        sentence: a string\n",
        "        p_prior: a dictionary of the prior probability\n",
        "        p_likelihood: a dictionary of words mapping to the probability\n",
        "    Output:\n",
        "        p: the probability of sentence with 0: negative, 1: positive\n",
        "\n",
        "    '''\n",
        "    # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
        "    words = basic_preprocess(sentence)\n",
        "\n",
        "    # Kh·ªüi t·∫°o gi√° tr·ªã x√°c su·∫•t ban ƒë·∫ßu l√† gi√° tr·ªã x√°c su·∫•t ti√™n nghi·ªám\n",
        "    p_neg = p_prior[0]\n",
        "    p_pos = p_prior[1]\n",
        "\n",
        "    for word in words:\n",
        "        # Ki·ªÉm tra xem word c√≥ t·ªìn t·∫°i trong p_likelihood hay kh√¥ng\n",
        "        if word in p_likelihood:\n",
        "            ### START CODE HERE\n",
        "            # nh√¢n x√°c su·∫•t ti√™n nghi·ªám v·ªõi x√°c su·∫•t likelihood c·ªßa c√°c t·ª´\n",
        "            p_neg *= p_likelihood[word][0]\n",
        "            p_pos *= p_likelihood[word][1]\n",
        "            ### END CODE HERE\n",
        "    return {'prob': {0: p_neg, 1: p_pos},\n",
        "            'label': 0 if p_neg > p_pos else 1}"
      ],
      "metadata": {
        "id": "LGg1ez0LlAiX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VzCU8cW2hn6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_prior, p_likelihood = train_naive_bayes(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpyFejWBhj_G",
        "outputId": "7996e674-7784-4b4f-83e2-97a246ec60c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V: 10840, N_pos: 41915, N_neg: 43321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict"
      ],
      "metadata": {
        "id": "tmSLK7P9kZ2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wHIIPH9ThtsK",
        "outputId": "3fa478a2-057a-4505-9eaa-67dc9b1eb4f2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bro:U wan cut hair anot,ur hair long Liao bo\\nMe:since ord liao,take it easy lor treat as save $ leave it longer :)\\nBro:LOL Sibei xialan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W74NTQf4kkXN",
        "outputId": "d78447e7-fce0-4874-ca20-892150dcce18"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_predict(test_x[0], p_prior, p_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nck1eRzk2CE",
        "outputId": "d044fa74-b1d4-456d-e6a3-a3f39051bec4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prob': {0: 1.103764144713296e-80, 1: 2.101225984564381e-79}, 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing accuracy"
      ],
      "metadata": {
        "id": "Q9x9IJqSlKWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = 0\n",
        "for sentence, label in zip(test_x, test_y):\n",
        "  pred = naive_bayes_predict(sentence, p_prior, p_likelihood)['label']\n",
        "\n",
        "  if pred == label:\n",
        "    acc+=1\n",
        "print(\"Accuracy\", acc/len(test_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvBxn74Xk6NA",
        "outputId": "9449c673-4852-4988-fc03-8d96b9818754"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGiqEGIQlgX3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}